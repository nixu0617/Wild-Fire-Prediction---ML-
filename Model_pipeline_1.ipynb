{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_XLmx5_N5yiR",
        "8Em_yP6I86ny",
        "GbGc8C7FH0X-",
        "jT2DgtQyNLv6",
        "hD7ndnzBQ2A1",
        "ykRH83AnNyr_",
        "V2km-0_ZN-FN",
        "5BFMyYfvOPHe",
        "ILsdg7T-f5P4",
        "eAbeAY_5UzNh",
        "CmbJjN8qhG3N",
        "R_nzMBrIvBpW",
        "dohF5WUKYZAt",
        "BhkfdUtb2bC7",
        "ysjogeG5_8FL",
        "sx2jtbWGAJIg",
        "6z7wjCWwOz8e",
        "XSAnGRIMKrzR",
        "vZx1fnupua7M",
        "5DnktQftzsRq",
        "8GBDCdxI5TBm",
        "uD0Ci-Bj0Ngj",
        "q_8q_Su0173Z",
        "oQpxby377DYF",
        "1cLuot9YePv6",
        "kwfHFhTseOpV",
        "nGSk2Y8nekFH",
        "VucBbVtne4sI",
        "rLzrG_ivfIgK"
      ],
      "authorship_tag": "ABX9TyMcA0WsWpRQvEpJZd82j06G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MapleWolfe/Milestone_2/blob/main/Model_pipeline_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### we are providing three ways to load the zip file data: please note that only one should be used.\n",
        "### run cells for only one of these three but not all threegoogle bucket\n",
        "\n",
        "### google bucket pre sets for data\n",
        "google_application_credentials = '/content/organic-reef-390716-609989a4c6da.json'\n",
        "bucket_name = 'fire_train_eval_test_bucket' #you need to name your bucket\n",
        "zip_file_name = 'next_day_wildfire.zip' #name of the zip file\n",
        "\n",
        "### google drive upload\n",
        "google_drive_location = '/content/drive/MyDrive/next_day_wildfire.zip'\n",
        "\n",
        "### if the zip file is uploaded to the same location as this notebook, start from the unzip cell:\n",
        "load_local_zip = '/content/next_day_wildfire.zip'\n",
        "\n",
        "### in the situation that any of the above code does not work:\n",
        "### please look under Unzipping file section of the notebook"
      ],
      "metadata": {
        "id": "GmEdhwIX9es0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model pipeline 1\n",
        "\n",
        "Hardware/system requirements:\n",
        "- CPU - minimum 64 cores\n",
        "- GPU - 2 Nvidia T4\n",
        "- RAM - Minimum 400 GB\n",
        "- Disk - Minimum 500 GB\n",
        "\n",
        "This notebook will take upto 24hrs depending on your hardware specifications"
      ],
      "metadata": {
        "id": "m4Nei-GK5UAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installs, imports, pre-sets"
      ],
      "metadata": {
        "id": "Uv1syv3gdvb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab7nSMjt3yqt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py\n",
        "!pip install google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#google import options\n",
        "from google.colab import drive\n",
        "from google.cloud import storage\n",
        "\n",
        "#general usage imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import gc\n",
        "import os\n",
        "import multiprocessing\n",
        "import pickle\n",
        "import json\n",
        "import joblib\n",
        "import zipfile\n",
        "\n",
        "#image processing\n",
        "import skimage\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "\n",
        "#sklearn preprocessing operations imports\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# unsupervised learning models\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "# model evaluation and metrics\n",
        "from sklearn.metrics import precision_score,recall_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#deeplearning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "#sklearn classifiers\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "# sklearn regression\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "#GPU imports\n",
        "import xgboost as xgb\n",
        "import cudf\n",
        "import cupy\n",
        "from cuml.naive_bayes import GaussianNB\n",
        "from cuml.naive_bayes import ComplementNB\n",
        "from cuml import LogisticRegression\n",
        "from cuml.ensemble import RandomForestClassifier\n",
        "\n",
        "#viaualization library:\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tc0JOf_l5_87"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cpus = multiprocessing.cpu_count()\n",
        "print(\"Number of available CPUs:\", num_cpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL2qYF3A7vbK",
        "outputId": "312ef5b1-f1ee-4e5f-a1f7-45459b55fd56"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available CPUs: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data using Google drive storage\n",
        "(this works on the free google colab not the paid colab instance from gcp market place)"
      ],
      "metadata": {
        "id": "_XLmx5_N5yiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's mount the drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# let's look into the zip file stored in the google drive\n",
        "load_local_zip = google_drive_location\n"
      ],
      "metadata": {
        "id": "JHwsb7d75xrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data from Google cloud storage"
      ],
      "metadata": {
        "id": "8Em_yP6I86ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = google_application_credentials\n",
        "client = storage.Client()\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "blob = bucket.blob(zip_file_name)\n",
        "blob.download_to_filename(zip_file_name)\n",
        "load_local_zip = zip_file_name"
      ],
      "metadata": {
        "id": "MCxeNi8k8_AI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzipping file\n",
        "(from here our code begins regardless of source choice)"
      ],
      "metadata": {
        "id": "GbGc8C7FH0X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wildfire_zip =  zipfile.ZipFile(load_local_zip, 'r')\n",
        "tf_record_file_names = wildfire_zip.namelist()\n",
        "\n",
        "print('number of TF records:', len(tf_record_file_names))\n",
        "print('file names of tf records within the zip:')\n",
        "print(tf_record_file_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsVRfqlsH2uX",
        "outputId": "0b5aa1b0-6fae-49d5-f8c5-6a04d4b93ab4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of TF records: 19\n",
            "file names of tf records within the zip:\n",
            "['next_day_wildfire_spread_eval_00.tfrecord', 'next_day_wildfire_spread_eval_01.tfrecord', 'next_day_wildfire_spread_test_00.tfrecord', 'next_day_wildfire_spread_test_01.tfrecord', 'next_day_wildfire_spread_train_00.tfrecord', 'next_day_wildfire_spread_train_01.tfrecord', 'next_day_wildfire_spread_train_02.tfrecord', 'next_day_wildfire_spread_train_03.tfrecord', 'next_day_wildfire_spread_train_04.tfrecord', 'next_day_wildfire_spread_train_05.tfrecord', 'next_day_wildfire_spread_train_06.tfrecord', 'next_day_wildfire_spread_train_07.tfrecord', 'next_day_wildfire_spread_train_08.tfrecord', 'next_day_wildfire_spread_train_09.tfrecord', 'next_day_wildfire_spread_train_10.tfrecord', 'next_day_wildfire_spread_train_11.tfrecord', 'next_day_wildfire_spread_train_12.tfrecord', 'next_day_wildfire_spread_train_13.tfrecord', 'next_day_wildfire_spread_train_14.tfrecord']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to read into one tf record at a time by unziiping one file at a time"
      ],
      "metadata": {
        "id": "jT2DgtQyNLv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzipping one file at a time\n",
        "def one_file_unzip(tf_record_file_name, zipfile_variable):\n",
        "  extracted_record_path = zipfile_variable.extract(tf_record_file_name)\n",
        "  raw_dataset = tf.data.TFRecordDataset(extracted_record_path)\n",
        "  return raw_dataset\n",
        "\n",
        "# yielding out one record at a time\n",
        "def extract_one_row(tf_record_dataset):\n",
        "  for i, raw_record in enumerate(tf_record_dataset.take(tf_record_dataset.cardinality().numpy())):\n",
        "    one_record_dict = {}\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "    for key, feature in example.features.feature.items():\n",
        "\n",
        "      kind = feature.WhichOneof('kind')\n",
        "      one_record_dict[key] = np.array(getattr(feature, kind).value).reshape(64,64)\n",
        "    yield one_record_dict"
      ],
      "metadata": {
        "id": "jebXCztTNQHG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Generation"
      ],
      "metadata": {
        "id": "rxvnr6JCMvBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### feature description given by dataset provider"
      ],
      "metadata": {
        "id": "hD7ndnzBQ2A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data variables\n",
        "\n",
        "INPUT_FEATURES = ['elevation', 'th', 'vs',  'tmmn', 'tmmx', 'sph',\n",
        "                  'pr', 'pdsi', 'NDVI', 'population', 'erc', 'PrevFireMask']\n",
        "\n",
        "OUTPUT_FEATURES = ['FireMask']\n",
        "\n",
        "\n",
        "# underlying feature value ranges:\n",
        "# (min_clip, max_clip, mean, standard deviation)\n",
        "\n",
        "feature_description_dict = {\n",
        "    # Elevation in m: between 0.1 percentile and 99.9 percentile\n",
        "    'elevation': (0.0, 3141.0, 657.3003, 649.0147),\n",
        "\n",
        "    # Palmer Drought Severity Index: between 0.1 percentile and 99.9 percentile\n",
        "    'pdsi': (-6.12974870967865, 7.876040384292651, -0.0052714925, 2.6823447),\n",
        "\n",
        "    #Vegetation index times 10,000: between -1 and 1\n",
        "    'NDVI': (-9821.0, 9996.0, 5157.625, 2466.6677),\n",
        "\n",
        "    # Precipitation in mm: between 0.0 and 99.9 percentile\n",
        "    'pr': (0.0, 44.53038024902344, 1.7398051, 4.482833),\n",
        "\n",
        "    # Specific humidity: between 0 and 1\n",
        "    'sph': (0., 1., 0.0071658953, 0.0042835088),\n",
        "\n",
        "    # Wind direction in degrees clockwise from north: between 0 and 360.\n",
        "    'th': (0., 360.0, 190.32976, 72.59854),\n",
        "\n",
        "    #Min temp: between 253.15 kelvin and 99.9 percentile\n",
        "    'tmmn': (253.15, 298.94891357421875, 281.08768, 8.982386),\n",
        "\n",
        "    #Max temp: between 253.15 kelvin and 99.9 percentile\n",
        "    'tmmx': (253.15, 315.09228515625, 295.17383, 9.815496),\n",
        "\n",
        "    # Wind speed in m/s: between 0. and 99.9 percentile\n",
        "    'vs': (0.0, 10.024310074806237, 3.8500874, 1.4109988),\n",
        "\n",
        "    # NFDRS fire danger index energy release component BTU's per square foot.\n",
        "    # 0., 99.9 percentile\n",
        "    'erc': (0.0, 106.24891662597656, 37.326267, 20.846027),\n",
        "\n",
        "    # Population density: between 0 and 99.9 percentile\n",
        "    'population': (0., 2534.06298828125, 25.531384, 154.72331),\n",
        "\n",
        "    # We don't want to normalize the FireMasks.\n",
        "    # 1 indicates fire, 0 no fire, -1 unlabeled data\n",
        "    'PrevFireMask': (-1., 1., 0., 1.),\n",
        "    'FireMask': (-1., 1., 0., 1.)\n",
        "}\n"
      ],
      "metadata": {
        "id": "E4-Gd5OVc94v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Creation Functions"
      ],
      "metadata": {
        "id": "ykRH83AnNyr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets define the min max scaling function\n",
        "def min_max_scaling(array,min_val,max_val):\n",
        "    scaled_array = np.clip((array - min_val) / (max_val - min_val), 0, 1)\n",
        "    return scaled_array\n",
        "\n",
        "# let's apply guassian smoothing\n",
        "def gaussian_smoothing(image_array,sigma_val):\n",
        "  smooth_array = skimage.filters.gaussian(image_array, sigma=1)\n",
        "  return smooth_array\n",
        "\n",
        "#lets get the rate of change and mean,\n",
        "def local_pixel_features(image_array,radius_val):\n",
        "  footprint = skimage.morphology.disk(radius_val)\n",
        "  gradient_array = skimage.filters.rank.gradient(image_array, footprint)\n",
        "  mean_array = skimage.filters.rank.mean(image_array, footprint)\n",
        "  return gradient_array,mean_array\n",
        "\n",
        "#use altitude edge to identify whether pixel is at a similar altitude as any pixel that has fire\n",
        "def fire_pixel_shared_altitude(row_dict, normalized_array, previous_day_fire = 'PrevFireMask'):\n",
        "  edges_array = skimage.feature.canny(normalized_array)\n",
        "  inverted_edges_array = np.logical_not(edges_array).astype(int)\n",
        "  edge_label_array = skimage.measure.label(inverted_edges_array)\n",
        "\n",
        "  previous_fire = row_dict[previous_day_fire]\n",
        "  fire_edge_labels = (edge_label_array*previous_fire)\n",
        "\n",
        "  unique_regions_with_fire = np.unique(fire_edge_labels.flatten())\n",
        "  non_zero_unique_regions = unique_regions_with_fire[unique_regions_with_fire != 0]\n",
        "\n",
        "  fire_at_same_altitude = np.isin(edge_label_array, non_zero_unique_regions).astype(int)\n",
        "  return fire_at_same_altitude\n",
        "\n",
        "def distance_to_fire(row_dict,feature):\n",
        "  # we need to clip the fire mask to account for -1 values (missing values where the satellite was unable to get a clear image)\n",
        "  # for now we take them as no fire objects, however we will not be accounting for these pixels in our model.\n",
        "  fire_mask_array = row_dict[feature].clip(0,1)\n",
        "  inverted_mask_array = 1 - fire_mask_array\n",
        "  distance_transform_array = distance_transform_edt(inverted_mask_array)\n",
        "  return distance_transform_array\n"
      ],
      "metadata": {
        "id": "i7krqq3gVEpk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to combine all features"
      ],
      "metadata": {
        "id": "V2km-0_ZN-FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's apply it on all features\n",
        "def build_features(record_dict,min_max_dict,sigma_val,radius_val):\n",
        "  feature_list = record_dict.keys()\n",
        "  output_feature_dict = {}\n",
        "  for a_feature in feature_list:\n",
        "    if a_feature not in ['PrevFireMask','FireMask']:\n",
        "     #min max scaling\n",
        "     feature_min = min_max_dict[a_feature][0]\n",
        "     feature_max = min_max_dict[a_feature][1]\n",
        "     scaled_array = min_max_scaling(record_dict[a_feature],feature_min,feature_max)\n",
        "     #guassian smoothing\n",
        "     smoothen_array = gaussian_smoothing(scaled_array,sigma_val)\n",
        "\n",
        "     #local pixel values: gradient values(rate of change), local mean val.\n",
        "     gradient_array,mean_array = local_pixel_features(smoothen_array,radius_val)\n",
        "\n",
        "     #lets now add these features to our output:\n",
        "     output_feature_dict[a_feature+'_'+'scaled_smoothened_values'] = smoothen_array.flatten()\n",
        "     output_feature_dict[a_feature+'_'+'local_gradient'] = gradient_array.flatten()\n",
        "     output_feature_dict[a_feature+'_'+'local_mean'] = mean_array.flatten()\n",
        "\n",
        "     #lets label pixels if they are at the same elevation (to account for cliffs/mountains/chasms) as the fire\n",
        "     # here we aren't using smoothened array\n",
        "    if a_feature == 'elevation':\n",
        "      fire_at_altitude_array = fire_pixel_shared_altitude(record_dict, scaled_array)\n",
        "      output_feature_dict['fire_at_similar_altitude'] = fire_at_altitude_array.flatten()\n",
        "     #lets move are features into a dict.\n",
        "\n",
        "    # get pixel eucledian distance from fire\n",
        "    if a_feature == 'PrevFireMask':\n",
        "      distance_array = distance_to_fire(record_dict,a_feature)\n",
        "      output_feature_dict['PrevFireMask'] = record_dict[a_feature].flatten()\n",
        "      output_feature_dict['distance_from_fire'] = distance_array.flatten()\n",
        "\n",
        "    if a_feature == 'FireMask':\n",
        "      output_feature_dict['FireMask'] = record_dict[a_feature].flatten()\n",
        "\n",
        "  return output_feature_dict\n"
      ],
      "metadata": {
        "id": "aqPsijxmOGiD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### function that uses all prior functions and creates csv"
      ],
      "metadata": {
        "id": "5BFMyYfvOPHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_df_save_csv(string_file_name,tf_record_names = tf_record_file_names, main_zip_file = wildfire_zip, feature_descriptions= feature_description_dict):\n",
        "  first_write = True\n",
        "  total_rows = 0\n",
        "  image_id = 0\n",
        "  large_df_list = []\n",
        "  column_names = []\n",
        "  csv_file_name = string_file_name + '.csv'\n",
        "  for a_tf_record in tf_record_names:\n",
        "    if string_file_name in a_tf_record:\n",
        "      print('started tf record: ', a_tf_record)\n",
        "      raw_dataset = one_file_unzip(a_tf_record, main_zip_file)\n",
        "      row_extraction_generator = extract_one_row(raw_dataset)\n",
        "      single_record_list = []\n",
        "      image_count = 0\n",
        "\n",
        "      for a_row in row_extraction_generator:\n",
        "        all_features_dict_array = build_features(a_row,feature_descriptions,sigma_val=1,radius_val=3)\n",
        "        column_names = all_features_dict_array.keys()\n",
        "        image_id += 1\n",
        "        image_count +=1\n",
        "        image_number_array = np.full(4096, image_id)\n",
        "        all_features_dict_array['image_id'] = image_number_array\n",
        "\n",
        "        if image_count == 1:\n",
        "          all_features_dataframe = cudf.DataFrame.from_dict(all_features_dict_array)\n",
        "        else:\n",
        "          single_row_df = cudf.DataFrame.from_dict(all_features_dict_array)\n",
        "          all_features_dataframe = all_features_dataframe.append(single_row_df, ignore_index=True)\n",
        "\n",
        "        if image_count >= 200:\n",
        "          single_record_list.append(all_features_dataframe)\n",
        "          image_count = 0\n",
        "\n",
        "      if image_count % 200 != 0:\n",
        "        single_record_list.append(all_features_dataframe)\n",
        "        image_count = 0\n",
        "\n",
        "      big_df = cudf.concat(single_record_list, ignore_index=True)\n",
        "      pandas_big_df = big_df.to_pandas()\n",
        "      total_rows += len(pandas_big_df)\n",
        "      if first_write == True:\n",
        "        pandas_big_df.to_csv(csv_file_name, mode='w', index=False, header=True)\n",
        "        first_write = False\n",
        "      else:\n",
        "        pandas_big_df.to_csv(csv_file_name, mode='a', index=False, header=False)\n",
        "\n",
        "  print('completed: ', a_tf_record)\n",
        "  print('csv output is complete')\n",
        "  print('output csv lenght',total_rows)\n",
        "  print('output csv image count: ', total_rows/4096)\n",
        "  print('number of expected images', image_id)\n",
        "  return None"
      ],
      "metadata": {
        "id": "Zk3Dea1qOOa0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating test, train and eval csv files"
      ],
      "metadata": {
        "id": "SCrhqe74OuUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print('we are making eval csv')\n",
        "make_df_save_csv('eval')\n",
        "\n",
        "print('we are making test csv')\n",
        "make_df_save_csv('test')\n",
        "\n",
        "print('we are making train csv')\n",
        "make_df_save_csv('train')\n",
        "\n",
        "del wildfire_zip\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "nhjNsGXlO1H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a6CfY1W4U13C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to read CSV files"
      ],
      "metadata": {
        "id": "xfkHu31RVDlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remember to add .csv at the end of file name\n",
        "def read_csv_in_chunks(file_name,number_images):\n",
        "  pixels_count = 64*64\n",
        "  size = number_images*pixels_count\n",
        "  file_string = '/content/' + file_name\n",
        "  return pd.read_csv(file_string, chunksize=size)\n",
        "\n",
        "def read_full_csv(file_name):\n",
        "  file_string = '/content/' + file_name\n",
        "  return pd.read_csv(file_string)"
      ],
      "metadata": {
        "id": "N_0vVCPKUyWK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to create feature and target variables\n"
      ],
      "metadata": {
        "id": "oLn0gqWnVHxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaner_1(df_chunk):\n",
        "  col_list = ['NDVI_scaled_smoothened_values', 'NDVI_local_gradient', 'NDVI_local_mean', 'tmmn_scaled_smoothened_values', 'tmmn_local_gradient', 'tmmn_local_mean', 'elevation_scaled_smoothened_values', 'elevation_local_gradient', 'elevation_local_mean', 'fire_at_similar_altitude', 'population_scaled_smoothened_values', 'population_local_gradient', 'population_local_mean', 'vs_scaled_smoothened_values', 'vs_local_gradient', 'vs_local_mean', 'pdsi_scaled_smoothened_values', 'pdsi_local_gradient', 'pdsi_local_mean', 'pr_scaled_smoothened_values', 'pr_local_gradient', 'pr_local_mean', 'tmmx_scaled_smoothened_values', 'tmmx_local_gradient', 'tmmx_local_mean', 'sph_scaled_smoothened_values', 'sph_local_gradient', 'sph_local_mean', 'th_scaled_smoothened_values', 'th_local_gradient', 'th_local_mean', 'distance_from_fire', 'erc_scaled_smoothened_values', 'erc_local_gradient', 'erc_local_mean']\n",
        "\n",
        "  original_previous_day_fire = df_chunk['PrevFireMask']\n",
        "  original_next_day_fire = df_chunk['FireMask']\n",
        "\n",
        "  #general cleaning for classifier and regressor\n",
        "  drop_neg_df = df_chunk[df_chunk['FireMask'] >=0]\n",
        "\n",
        "  #only regressor selection\n",
        "  regressor_target = drop_neg_df['FireMask']\n",
        "\n",
        "  #cleaning specifically for the classifier\n",
        "  classifier_target = np.where(regressor_target > 0, 1, 0)\n",
        "  dropped_chunk = drop_neg_df.drop(labels=['PrevFireMask','FireMask','image_id'], axis=1)\n",
        "\n",
        "  return dropped_chunk[col_list],regressor_target,classifier_target, original_previous_day_fire, original_next_day_fire"
      ],
      "metadata": {
        "id": "voaiTGQnXDvj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying the prior functions on the downloaded CSV files + scaling data"
      ],
      "metadata": {
        "id": "x8O4bJorXMg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "train_df = read_full_csv('train.csv')\n",
        "print('train loaded')\n",
        "train_cleaned_df,train_regressor_target,train_classifier_target, train_original_previous_day_fire, train_original_next_day_fire = cleaner_1(train_df)\n",
        "del train_df\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "#evaluation\n",
        "eval_df = read_full_csv('eval.csv')\n",
        "print('eval loaded')\n",
        "eval_cleaned_df,eval_regressor_target,eval_classifier_target, eval_original_previous_day_fire, eval_original_next_day_fire = cleaner_1(eval_df)\n",
        "del eval_df\n",
        "gc.collect()\n",
        "\n",
        "#test\n",
        "test_df = read_full_csv('test.csv')\n",
        "print('test loaded')\n",
        "test_cleaned_df,test_regressor_target,test_classifier_target, test_original_previous_day_fire, test_original_next_day_fire = cleaner_1(test_df)\n",
        "del test_df\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6CGDGqbXJkQ",
        "outputId": "4f26a8f5-62a2-44a9-f138-7df9e2b49cd5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loaded\n",
            "eval loaded\n",
            "test loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised learning"
      ],
      "metadata": {
        "id": "H060TgFeRYWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard Scaling"
      ],
      "metadata": {
        "id": "ILsdg7T-f5P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "print('train data scaling started')\n",
        "train_data_scaled = scaler.fit_transform(train_cleaned_df)\n",
        "del train_cleaned_df\n",
        "gc.collect()\n",
        "\n",
        "print('eval data scaling started')\n",
        "eval_data_scaled = scaler.transform(eval_cleaned_df)\n",
        "\n",
        "print('test data scaling started')\n",
        "test_data_scaled = scaler.transform(test_cleaned_df)\n",
        "del test_cleaned_df\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNk2Eserf8UE",
        "outputId": "aec3ec13-b399-4bb2-cba7-b4e3491603e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data scaling started\n",
            "eval data scaling started\n",
            "test data scaling started\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA"
      ],
      "metadata": {
        "id": "eAbeAY_5UzNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building tuned PCA models"
      ],
      "metadata": {
        "id": "CmbJjN8qhG3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_param_grid = {'n_components': [4,6,8,10,12,14,16,18]}\n",
        "pca_storage_dict = {}\n",
        "model_counter = 0\n",
        "\n",
        "for params in ParameterGrid(pca_param_grid):\n",
        "  model_counter +=1\n",
        "  print('initializing PCA for param: ', params)\n",
        "  pca_model = PCA(**params)\n",
        "  chunk_counter = 0\n",
        "  pca_model.fit(train_data_scaled)\n",
        "  print('pca completed for model : ', model_counter)\n",
        "\n",
        "  pca_model_name_string = 'pca_model_'+str(model_counter)\n",
        "  pca_storage_dict[pca_model_name_string] = [params,{'explained_variance': list(pca_model.explained_variance_)},{'explained_variance_ratio':list(pca_model.explained_variance_ratio_)}]\n",
        "  print('storing pca file')\n",
        "  with open(pca_model_name_string, 'wb') as pca_file:\n",
        "    pickle.dump(pca_model, pca_file)\n",
        "\n",
        "print('storing scalar model')\n",
        "with open('standard_scalar_model', 'wb') as scaler_file:\n",
        "  pickle.dump(scaler, scaler_file)\n",
        "\n",
        "print('storing pca performance')\n",
        "with open('pca_model_performance.json', 'w') as pca_metric_json:\n",
        "    json.dump(pca_storage_dict, pca_metric_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6ogaSO7YiuW",
        "outputId": "5662536a-f471-4467-a6bf-44312ca90748"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializing PCA for param:  {'n_components': 4}\n",
            "pca completed for model :  1\n",
            "storing pca file\n",
            "initializing PCA for param:  {'n_components': 6}\n",
            "pca completed for model :  2\n",
            "storing pca file\n",
            "initializing PCA for param:  {'n_components': 8}\n",
            "pca completed for model :  3\n",
            "storing pca file\n",
            "initializing PCA for param:  {'n_components': 10}\n",
            "pca completed for model :  4\n",
            "storing pca file\n",
            "initializing PCA for param:  {'n_components': 12}\n",
            "pca completed for model :  5\n",
            "storing pca file\n",
            "initializing PCA for param:  {'n_components': 14}\n",
            "pca completed for model :  6\n",
            "storing pca file\n",
            "initializing PCA for param:  {'n_components': 16}\n",
            "pca completed for model :  7\n",
            "storing pca file\n",
            "initializing PCA for param:  {'n_components': 18}\n",
            "pca completed for model :  8\n",
            "storing pca file\n",
            "storing scalar model\n",
            "storing pca performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PCA model evaluation plot"
      ],
      "metadata": {
        "id": "R_nzMBrIvBpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_file = open('/content/pca_model_performance.json')\n",
        "pca_models = json.load(pca_file)\n",
        "\n",
        "x = list()\n",
        "y = list()\n",
        "for n,model in enumerate(pca_models.keys()):\n",
        "    x.append(pca_models[model][0]['n_components'])\n",
        "    idx = pca_models[model][0]['n_components'] - 1\n",
        "    #y = np.sum(pca_models[model][1]['explained_variance'])\n",
        "    y.append(np.cumsum(pca_models[model][2]['explained_variance_ratio'])[idx])\n",
        "\n",
        "plt.plot(x,y,marker='o', linestyle='--', color='b')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative variance (%)')\n",
        "plt.title('The number of components needed to explain variance')"
      ],
      "metadata": {
        "id": "SZ8sfseQhFFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the best PCA is Model 8 that. gives us about 18 components\n",
        "with open('/content/pca_model_8', 'rb') as pca_file:\n",
        "    loaded_pca_model = pickle.load(pca_file)"
      ],
      "metadata": {
        "id": "1ECaLv9j2JHZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kmeans"
      ],
      "metadata": {
        "id": "dohF5WUKYZAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K means cluster evaluation functions"
      ],
      "metadata": {
        "id": "BhkfdUtb2bC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_evaluation(eval_df, cluster_model):\n",
        "    print('evaluation start')\n",
        "    eval_labels = cluster_model.predict(eval_df)\n",
        "    inertia = cluster_model.inertia_\n",
        "    calinski = calinski_harabasz_score(eval_df, eval_labels)\n",
        "    davies_bouldin = davies_bouldin_score(eval_df, eval_labels)\n",
        "    # we are no longer calculating silhouette score as it performs pairwise calculations that grow exponentially with data\n",
        "    #silhouette = silhouette_score(eval_df, eval_labels)\n",
        "    print('evaluation complete')\n",
        "    return inertia, calinski, davies_bouldin"
      ],
      "metadata": {
        "id": "_hMf_TqNYiK_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-means without PCA"
      ],
      "metadata": {
        "id": "ysjogeG5_8FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_params_kmeans(file,scaling_model,pca_model,cluster_list=[8,32,64],initialisation_list = ['k-means++', 'random'], random_state = [0]):\n",
        "  k_means_param_grid = {'n_clusters': cluster_list, 'init': initialisation_list, 'random_state' : random_state, 'batch_size' : [1024*num_cpus]}\n",
        "  for params in ParameterGrid(k_means_param_grid):\n",
        "    print('initializing kmeans for param: ', params)\n",
        "    csv_chunks_generator = read_csv_in_chunks(file,1000)\n",
        "    K_means_model = MiniBatchKMeans(**params)\n",
        "    counter = 0\n",
        "    for a_chunk in csv_chunks_generator:\n",
        "      features_df,_,_,_,_ = cleaner_1(a_chunk)\n",
        "      scaled_df = scaling_model.transform(features_df)\n",
        "      K_means_model.partial_fit(scaled_df)\n",
        "      print('iteration completed: ', counter)\n",
        "      counter+=1\n",
        "    yield K_means_model, params"
      ],
      "metadata": {
        "id": "boQ55qdMRai6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_builders = search_params_kmeans(file='train.csv',scaling_model = scaler, pca_model = loaded_pca_model)\n",
        "model_perform_dict ={}\n",
        "model_counter = 0\n",
        "\n",
        "#this where a lot of time will go, it will iterate over each model across grid search\n",
        "for a_kmean_model, kmean_params in model_builders:\n",
        "  model_counter +=1\n",
        "  print('initializing evaluation')\n",
        "  inertia, calinski, davies_bouldin = cluster_evaluation(eval_cleaned_df, a_kmean_model)\n",
        "  print('evaluation complete')\n",
        "\n",
        "  model_name = 'kmean_model_no_pca'+str(model_counter)\n",
        "  model_perform_dict[model_name]=[kmean_params,inertia, calinski, davies_bouldin]\n",
        "  print('storing model')\n",
        "  with open(model_name, 'wb') as model_file:\n",
        "    pickle.dump(a_kmean_model, model_file)\n",
        "\n",
        "#outputing our evaluation metrics for all the models\n",
        "with open('kmean_model_performance.json', 'w') as kmeans_metric_json:\n",
        "    json.dump(model_perform_dict, kmeans_metric_json)\n"
      ],
      "metadata": {
        "id": "0qc1ywol3CIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-means with PCA"
      ],
      "metadata": {
        "id": "sx2jtbWGAJIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_params_kmeans_pca(file,scaling_model,pca_model,cluster_list=[8,32,64],initialisation_list = ['k-means++', 'random'], random_state = [0]):\n",
        "  k_means_param_grid = {'n_clusters': cluster_list, 'init': initialisation_list, 'random_state' : random_state, 'batch_size' : [1024*num_cpus]}\n",
        "  for params in ParameterGrid(k_means_param_grid):\n",
        "    print('initializing kmeans for param: ', params)\n",
        "    csv_chunks_generator = read_csv_in_chunks(file,1000)\n",
        "    K_means_model = MiniBatchKMeans(**params)\n",
        "    counter = 0\n",
        "    for a_chunk in csv_chunks_generator:\n",
        "      features_df,_,_,_,_ = cleaner_1(a_chunk)\n",
        "      scaled_df = scaling_model.transform(features_df)\n",
        "      out_pca_df = pca_model.transform(scaled_df)\n",
        "      K_means_model.partial_fit(out_pca_df)\n",
        "      print('iteration completed: ', counter)\n",
        "      counter+=1\n",
        "    yield K_means_model, params"
      ],
      "metadata": {
        "id": "BqgrbCzpBOmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_builders = search_params_kmeans_pca(file='train.csv',scaling_model = scaler, pca_model = loaded_pca_model)\n",
        "model_perform_dict_pca ={}\n",
        "model_counter = 0\n",
        "eval_pca = loaded_pca_model.transform(eval_data_scaled)\n",
        "#this where a lot of time will go, it will iterate over each model across grid search\n",
        "for a_kmean_model, kmean_params in model_builders:\n",
        "  model_counter +=1\n",
        "  print('initializing evaluation')\n",
        "  inertia, calinski, davies_bouldin = cluster_evaluation(eval_pca, a_kmean_model)\n",
        "  print('evaluation complete')\n",
        "\n",
        "  model_name = 'kmean_model_'+str(model_counter)\n",
        "  model_perform_dict_pca[model_name]=[kmean_params,inertia, calinski, davies_bouldin]\n",
        "  print('storing model')\n",
        "  with open(model_name, 'wb') as model_file:\n",
        "    pickle.dump(a_kmean_model, model_file)\n",
        "#outputing our evaluation metrics for all the models\n",
        "with open('kmean_pca_model_performance.json', 'w') as kmeans_metric_json:\n",
        "    json.dump(model_perform_dict, kmeans_metric_json)"
      ],
      "metadata": {
        "id": "wOUVC0R6AGkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### k-means plot"
      ],
      "metadata": {
        "id": "bwN6NrJKGQd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_json(path):\n",
        "    kmeans_with_pca = path\n",
        "    df_with_pca = pd.read_json(kmeans_with_pca)\n",
        "    pca = df_with_pca.iloc[1:, ]\n",
        "    result = pca.apply(np.vectorize(lambda x: x[1]))\n",
        "    result['metrics']= ['inertia', 'Calinski', 'davies_bouldin']\n",
        "    pca_df = result.set_index('metrics').transpose()\n",
        "    normalized_df_wpca=(pca_df-pca_df.min())/(pca_df.max()-pca_df.min())\n",
        "    return normalized_df_wpca\n",
        "\n",
        "#create dataframe for plot\n",
        "def metric_df(metric):\n",
        "    metric_df = pd.DataFrame([df_wpca[metric], df_nopca[metric]]).transpose()\n",
        "    metric_df.set_axis(['metric' + '_pca','metric' + '_no_pca'], axis = 1)\n",
        "    return metric_df\n",
        "\n",
        "#plot generation\n",
        "def generate_bar(metric):\n",
        "    ax = metric_df(metric).plot.bar()\n",
        "    ax.set_ylabel('Normalized'+ metric +'Score')\n",
        "    ax.legend(['PCA', 'no_PCA'])\n",
        "    ax.set_title(metric + ' Comparison for models with/wo PCA')\n",
        "\n",
        "    for tick in ax.get_xticklabels():\n",
        "        tick.set_rotation(45)"
      ],
      "metadata": {
        "id": "Ocq56WovHFbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_performance_with_pca\n",
        "df_wpca= read_json('/content/kmean_pca_model_performance.json')\n",
        "\n",
        "#model_performance_no_pca\n",
        "df_nopca= read_json('/content/kmean_model_performance.json')\n"
      ],
      "metadata": {
        "id": "DAHPGdSQKakv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_bar('inertia')"
      ],
      "metadata": {
        "id": "rk9A0De8LCcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_bar('Calinski')"
      ],
      "metadata": {
        "id": "7H7YDynFLlBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_bar('davies_bouldin')"
      ],
      "metadata": {
        "id": "G0Qs3aTBLg-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kmeans model chosen based on explanation in the report:\n",
        "with open('/content/kmean_model_1', 'rb') as kmean_file:\n",
        "    loaded_kmean_model = pickle.load(kmean_file)"
      ],
      "metadata": {
        "id": "sCD6ljgYGJb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised Learning"
      ],
      "metadata": {
        "id": "p632A8HrIj8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/standard_scalar_model', 'rb') as ss_file:\n",
        "    loaded_scalar_model = pickle.load(ss_file)"
      ],
      "metadata": {
        "id": "n722nTuLL0uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preperation for supervised training"
      ],
      "metadata": {
        "id": "GP-k5FebNaJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('initializing train pca')\n",
        "train_data_pca = loaded_pca_model.transform(train_data_scaled)\n",
        "del train_data_scaled\n",
        "gc.collect()\n",
        "\n",
        "print('getting train cluster labels')\n",
        "train_cluster_labels = loaded_kmean_model.predict(train_data_pca)\n",
        "\n",
        "print('initializing eval pca')\n",
        "eval_data_pca = loaded_pca_model.transform(eval_data_scaled)\n",
        "del eval_data_scaled\n",
        "gc.collect()\n",
        "\n",
        "print('getting eval cluster labels')\n",
        "eval_cluster_labels = loaded_kmean_model.predict(eval_data_pca)\n",
        "\n",
        "\n",
        "print('initializing test pca')\n",
        "test_data_pca = loaded_pca_model.transform(test_data_scaled)\n",
        "del test_data_scaled\n",
        "gc.collect()\n",
        "\n",
        "print('getting test cluster labels')\n",
        "test_cluster_labels = loaded_kmean_model.predict(test_data_pca)\n"
      ],
      "metadata": {
        "id": "URlmdWW-NX4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Breaking training data into clusters function"
      ],
      "metadata": {
        "id": "6z7wjCWwOz8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def break_cluster(pca_data,cluster_labels,supervised_target):\n",
        "  unique_labels = list(np.unique(cluster_labels))\n",
        "  storage_dict={}\n",
        "  for a_label in unique_labels:\n",
        "    label_index = np.where(cluster_labels == a_label)[0]\n",
        "    feature_data = pca_data[label_index]\n",
        "    target_data = supervised_target[label_index]\n",
        "    yield a_label,feature_data,target_data"
      ],
      "metadata": {
        "id": "jY12OGR_OzGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier Model building"
      ],
      "metadata": {
        "id": "Gb4ok8QnKmXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic regression"
      ],
      "metadata": {
        "id": "XSAnGRIMKrzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_train(a_label,feature_df,target_array,penalty = ['l2']):\n",
        "  model_counter = 0\n",
        "  hyper_params ={'penalty': penalty}\n",
        "  name_param = {}\n",
        "  for params in ParameterGrid(hyper_params):\n",
        "    print('cluster: ', a_label, ', logistic regression for params: ', params)\n",
        "    model_counter+=1\n",
        "    print('initializing training of logistic regression')\n",
        "    lrs = LogisticRegression(**params)\n",
        "    lrs.fit(feature_df,target_array)\n",
        "    print('training complete')\n",
        "    print('saving model...')\n",
        "    model_name = 'cluster_'+str(a_label)+'_logistic_model_'+str(model_counter)\n",
        "    with open(model_name, 'wb') as model_file:\n",
        "      pickle.dump(lrs, model_file)\n",
        "    print('model saved')\n",
        "    name_param[model_name] = params\n",
        "  return name_param\n"
      ],
      "metadata": {
        "id": "bpn5fQDfKqFl"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SGD CLASSIFIER"
      ],
      "metadata": {
        "id": "vZx1fnupua7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd_train(a_label,feature_df,target_array,penalty = ['l1', 'l2', 'elasticnet'],random_state=[0],n_jobs=[-1]):\n",
        "  model_counter = 0\n",
        "  hyper_params ={'penalty': penalty,'random_state':random_state,'n_jobs':n_jobs}\n",
        "  name_param = {}\n",
        "  for params in ParameterGrid(hyper_params):\n",
        "    print('cluster: ', a_label, ', SGD for params: ', params)\n",
        "    model_counter+=1\n",
        "    print('initializing training of SGD ')\n",
        "    sgd = SGDClassifier(**params)\n",
        "    sgd.fit(feature_df,target_array)\n",
        "    print('training complete')\n",
        "    print('saving model...')\n",
        "    model_name = 'cluster_'+str(a_label)+'_SGD_model_'+str(model_counter)\n",
        "    with open(model_name, 'wb') as model_file:\n",
        "      pickle.dump(sgd, model_file)\n",
        "    print('model saved')\n",
        "    name_param[model_name] = params\n",
        "  return name_param\n"
      ],
      "metadata": {
        "id": "MP4ghcs-Udud"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "5DnktQftzsRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_train(a_label,feature_df,target_array,n_estimators = [100,200,400],min_samples_split = [4096],random_state=[0]):\n",
        "  model_counter = 0\n",
        "  hyper_params ={'n_estimators': n_estimators,'random_state':random_state}\n",
        "  name_param = {}\n",
        "  for params in ParameterGrid(hyper_params):\n",
        "    print('cluster: ', a_label, ', random forest for params: ', params)\n",
        "    model_counter+=1\n",
        "    print('initializing training of random forest')\n",
        "    rfc = RandomForestClassifier(**params)\n",
        "    rfc.fit(feature_df,target_array)\n",
        "    print('training complete')\n",
        "    print('saving model...')\n",
        "    model_name = 'cluster_'+str(a_label)+'_random_forest_model_'+str(model_counter)\n",
        "    with open(model_name, 'wb') as model_file:\n",
        "      pickle.dump(rfc, model_file)\n",
        "    print('model saved')\n",
        "    name_param[model_name] = params\n",
        "  return name_param"
      ],
      "metadata": {
        "id": "EkYv-Wt_yqGR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGB classifier"
      ],
      "metadata": {
        "id": "8GBDCdxI5TBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_train(a_label,feature_df,target_array,n_estimators = [100,200,400],tree_method =['gpu_hist'], objective = ['binary:logistic'] ):\n",
        "  model_counter = 0\n",
        "  hyper_params ={'n_estimators': n_estimators,'tree_method':tree_method, 'objective':objective}\n",
        "  name_param = {}\n",
        "  for params in ParameterGrid(hyper_params):\n",
        "    print('cluster: ', a_label, ', xgb for params: ', params)\n",
        "    model_counter+=1\n",
        "    print('initializing training of random forest')\n",
        "    xgc = xgb.XGBClassifier(**params)\n",
        "    # optimizing for gpu usage\n",
        "    xgc.fit(feature_df,target_array)\n",
        "    print('training complete')\n",
        "    print('saving model...')\n",
        "    model_name = 'cluster_'+str(a_label)+'_xgb_model_'+str(model_counter)\n",
        "    with open(model_name, 'wb') as model_file:\n",
        "      pickle.dump(xgc, model_file)\n",
        "    print('model saved')\n",
        "    name_param[model_name] = params\n",
        "  return name_param"
      ],
      "metadata": {
        "id": "jiLYrj945W0O"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Complement Naive Bayes"
      ],
      "metadata": {
        "id": "uD0Ci-Bj0Ngj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complement_nb_train(a_label,feature_df,target_array):\n",
        "  name_param = {}\n",
        "  print('cluster: ', a_label, ', Complement for params: ',)\n",
        "  model_counter=1\n",
        "  print('initializing training of ComplementNB')\n",
        "  cnb = GaussianNB()\n",
        "  cnb.fit(feature_df,target_array)\n",
        "  print('training complete')\n",
        "  print('saving model...')\n",
        "  model_name = 'cluster_'+str(a_label)+'_ComplementNB_'+str(model_counter)\n",
        "  with open(model_name, 'wb') as model_file:\n",
        "    pickle.dump(cnb, model_file)\n",
        "  print('model saved')\n",
        "  name_param[model_name] = 'default params'\n",
        "  return name_param"
      ],
      "metadata": {
        "id": "UQTJN5370Ngy"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "q_8q_Su0173Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_nb_train(a_label,feature_df,target_array):\n",
        "  name_param = {}\n",
        "  print('cluster: ', a_label, ', gaussian for params: ',)\n",
        "  model_counter=1\n",
        "  print('initializing training of guassianNB')\n",
        "  gnb = GaussianNB()\n",
        "  gnb.fit(feature_df,target_array)\n",
        "  print('training complete')\n",
        "  print('saving model...')\n",
        "  model_name = 'cluster_'+str(a_label)+'_guassianNB_'+str(model_counter)\n",
        "  with open(model_name, 'wb') as model_file:\n",
        "    pickle.dump(gnb, model_file)\n",
        "  print('model saved')\n",
        "  name_param[model_name] = 'default params'\n",
        "  return name_param"
      ],
      "metadata": {
        "id": "3i78PXRj173a"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### classifier training"
      ],
      "metadata": {
        "id": "oQpxby377DYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_dict = {}\n",
        "cluster = break_cluster(train_data_pca,train_cluster_labels,train_classifier_target)\n",
        "for label,feature,target in cluster:\n",
        "  print(label, len(feature),len(target))\n",
        "  print(np.unique(target))\n",
        "  print(type(target))\n",
        "  log_dict = logistic_train(label,feature,target)\n",
        "  gd_dict = sgd_train(label,feature,target)\n",
        "  rfc_dict = random_forest_train(label,feature,target)\n",
        "  xgb_dict = xgb_train(label,feature,target)\n",
        "  cnb_dict = complement_nb_train(label,feature,target)\n",
        "  gnb_dict = gaussian_nb_train(label,feature,target)\n",
        "  main_dict[label] = [log_dict,sgd_dict,rfc_dict,xgb_dict,cnb_dict,gnb_dict]\n",
        "\n",
        "save_dict = {}\n",
        "for key,val in main_dict.items():\n",
        "  save_dict[str(key)] = val\n",
        "\n",
        "# writing out dict as json\n",
        "with open('classiier_id_dict.json', 'w') as clf_dict:\n",
        "  json.dump(save_dict, clf_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "xiUwqbfU69jt",
        "outputId": "1d464c1c-379a-4847-92b3-bba70e8446fb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-950b3362ae8c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmain_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreak_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_pca\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_cluster_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_classifier_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'break_cluster' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dict = {}\n",
        "for key,val in main_dict.items():\n",
        "  save_dict[str(key)] = val\n",
        "\n",
        "# writing out dict as json\n",
        "with open('classiier_id_dict.json', 'w') as clf_dict:\n",
        "  json.dump(save_dict, clf_dict)"
      ],
      "metadata": {
        "id": "4OO_Ep8NjDVa"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auto Encoder generative Model\n"
      ],
      "metadata": {
        "id": "rltz3YZeq4kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1RX2UhwkruhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_feature(file_string):\n",
        "  if file_string == 'train':\n",
        "    feature_col = train_original_previous_day_fire.values\n",
        "    target_col = train_original_next_day_fire.values\n",
        "  if file_string == 'test':\n",
        "    feature_col = test_original_previous_day_fire.values\n",
        "    target_col = test_original_next_day_fire.values\n",
        "  if file_string == 'eval':\n",
        "    feature_col = eval_original_previous_day_fire.values\n",
        "    target_col = eval_original_next_day_fire.values\n",
        "\n",
        "  chunk_count = int(len(feature_col)/(64*64))\n",
        "  feature_list = np.array_split(feature_col, chunk_count)\n",
        "  target_list = np.array_split(target_col, chunk_count)\n",
        "\n",
        "  for a_feature,a_target in zip(feature_list,target_list):\n",
        "    yield a_feature.reshape(64,64), a_target.reshape(64,64)"
      ],
      "metadata": {
        "id": "W_9HDnokrHNy"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Auto-Encoder"
      ],
      "metadata": {
        "id": "lj7S-B3wrU9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "parameters = {\n",
        "    'encoding_dim': [64],  # Number of units in the bottleneck layer\n",
        "    'epochs': [10],  # Number of training epochs\n",
        "}\n",
        "\n",
        "input_dim = 64 # input feature count\n",
        "for params in ParameterGrid(parameters):\n",
        "  encoding_dim = params['encoding_dim'] #the number of features post reduction\n",
        "  input_data = Input(shape=(input_dim,))\n",
        "\n",
        "  encoded = Dense(encoding_dim*2, activation='relu')(input_data)\n",
        "  encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
        "  decoded = Dense(encoding_dim*2, activation='relu')(encoded)\n",
        "  decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
        "  autoencoder = Model(input_data, decoded)\n",
        "\n",
        "# Compile the autoencoder\n",
        "  autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Training the autoencoder on GPU in batch\n",
        "  with tf.device('/GPU:0'):\n",
        "    for feature,target in auto_feature('train'):\n",
        "      autoencoder.fit(feature,target, epochs=params['epochs'], shuffle=True)\n",
        "  file_string = 'autoencoder_generator'+'.h5'\n",
        "  autoencoder.save(file_string)"
      ],
      "metadata": {
        "id": "dfj_Ygp2rXcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = load_model('/content/autoencoder_generator.h5')\n",
        "for threshold in [0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
        "  accuracy_list = []\n",
        "  for a_predict, a_target in auto_feature('eval'):\n",
        "    binary_prediction = np.where(a_predict > threshold, 1, 0)\n",
        "    accuracy = accuracy_score(a_target, binary_prediction)\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "mean_dict = {}\n",
        "for key, val in accuracy_dict.items():\n",
        "  mean_dict[key] =  np.mean(val)"
      ],
      "metadata": {
        "id": "8ZqR8MjZ1gW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "h6TiVhJrSgf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to evaluate the dataset for only when ground truth is 1 [Fire]"
      ],
      "metadata": {
        "id": "1cLuot9YePv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_fire_break(feature_data, label_data):\n",
        "  '''\n",
        "  Split the dataset based on present fire 0 and 1 for prediction/accuracy comparisons\n",
        "  '''\n",
        "  ind = np.where(label_data == 1)[0]\n",
        "  reduced_feature_data = feature_data[ind]\n",
        "  reduced_label_data = label_data[ind]\n",
        "  return reduced_feature_data, reduced_label_data"
      ],
      "metadata": {
        "id": "jEhYS-OSSje9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### All Supervised Model evaluations"
      ],
      "metadata": {
        "id": "kwfHFhTseOpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content'\n",
        "model_dict = {}\n",
        "model_list = ['ComplementNB_1','guassianNB_1','logistic_model_1','random_forest_model_1','random_forest_model_2','random_forest_model_3','SGD_model_1','SGD_model_2','SGD_model_3','xgb_model_1','xgb_model_2','xgb_model_3']\n",
        "\n",
        "\n",
        "cl = break_cluster(eval_data_pca,eval_cluster_labels,eval_classifier_target)\n",
        "\n",
        "for label,feature,target in cl:\n",
        "  feats, tar = pos_fire_break(feature, target)\n",
        "  for m in model_list:\n",
        "    #Try to open pickled model data - some may not open due to truncation\n",
        "    #This could be an issue from how we allocated cluster data and then trained the model\n",
        "    try:\n",
        "      with open(base_path+'/cluster_'+str(label)+\"_\"+m,'rb') as file:\n",
        "        temp_model = pickle.load(file) #load in model\n",
        "    except:\n",
        "      print(temp_model, \"pickle data was truncated - cannot run\")\n",
        "      break\n",
        "\n",
        "    #truncated name for use in the model_dict\n",
        "    truncated_file_name = str(file).split('/')[-1].split('>')[0].split('\\'')[0]\n",
        "\n",
        "    #Try to run 5 Fold CV for all eval data\n",
        "    kf = KFold(n_splits=5)\n",
        "    fold = 1\n",
        "    acc,pre,rec,f1 = [],[],[],[]\n",
        "    for eval_ind in kf.split(feature):\n",
        "      y_pred = temp_model.predict(feature)\n",
        "      acc.append(accuracy_score(target,y_pred))\n",
        "      pre.append(precision_score(target,y_pred))\n",
        "      rec.append(recall_score(target,y_pred))\n",
        "      f1.append(f1_score(target,y_pred))\n",
        "\n",
        "      fold += 1\n",
        "    cv_scores = {'accuracy':np.mean(acc),'precision':np.mean(pre),'recall':np.mean(rec),'F1':np.mean(f1)}\n",
        "    model_dict[truncated_file_name] = cv_scores\n",
        "\n",
        "    #Try to run 5 fold CV on reduced data\n",
        "    #Failure of run may be due to lack in present fire data labels\n",
        "    try:\n",
        "      kf = KFold(n_splits=5)\n",
        "      fold = 1\n",
        "      acc,pre,rec,f1 = [],[],[],[]\n",
        "      for eval_ind in kf.split(feats):\n",
        "        y_pred = temp_model.predict(feats)\n",
        "        acc.append(accuracy_score(tar,y_pred))\n",
        "        pre.append(precision_score(tar,y_pred))\n",
        "        rec.append(recall_score(tar,y_pred))\n",
        "        f1.append(f1_score(tar,y_pred))\n",
        "        fold += 1\n",
        "      cv_scores_2 = {'accuracy':np.mean(acc),'precision':np.mean(pre),'recall':np.mean(rec),'F1':np.mean(f1)}\n",
        "\n",
        "      model_dict[truncated_file_name+'_reduced'] = cv_scores_2\n",
        "    except:\n",
        "      print(\"Failed Reduced CV for Cluster\",label,\"Model\",m)\n",
        "\n",
        "model_df = pd.DataFrame(model_dict)\n",
        "#Clear up some memory\n",
        "del temp_model\n",
        "del cl\n",
        "del feats\n",
        "del tar"
      ],
      "metadata": {
        "id": "RXxsVaGyck0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Evaluation DF for visualization"
      ],
      "metadata": {
        "id": "nGSk2Y8nekFH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HqdeHcAnDew"
      },
      "outputs": [],
      "source": [
        "# Mean together accross different clusters\n",
        "model_list = ['ComplementNB_1','guassianNB_1','logistic_model_1','random_forest_model_1','random_forest_model_2','random_forest_model_3','SGD_model_1','SGD_model_2','SGD_model_3','xgb_model_1','xgb_model_2','xgb_model_3']\n",
        "model_grouped_dict = {}\n",
        "for mod in model_list:\n",
        "  mod_list = []\n",
        "  mod_reduced_list = []\n",
        "  for each in model_df.columns:\n",
        "    if str(mod) in str(each) and \"reduced\" in str(each):\n",
        "      mod_reduced_list.append(each)\n",
        "    elif str(mod) in str(each):\n",
        "      mod_list.append(each)\n",
        "  model_grouped_dict[mod] = model_df[mod_list].mean(axis=1)\n",
        "  model_grouped_dict[mod+'_reduced'] = model_df[mod_reduced_list].mean(axis=1)\n",
        "#Finalized dataframe of important information\n",
        "DF = pd.DataFrame(model_grouped_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_cols = [col for col in DF.columns if 'reduced' in col]\n",
        "non_red_cols = [col for col in DF.columns if 'reduced' not in col]\n",
        "print(\"Reduced data metrics: \\n\",DF[reduced_cols].idxmax(axis=1))\n",
        "print(\"Data metrics: \\n\",DF[non_red_cols].idxmax(axis=1))\n",
        "\n",
        "#Best models for reduced data\n",
        "red_scores = DF[set(DF[reduced_cols].idxmax(axis=1))]\n",
        "print(red_scores)\n",
        "\n",
        "#Best models for data\n",
        "non_red_scores = DF[set(DF[non_red_cols].idxmax(axis=1))]\n",
        "print(non_red_scores)"
      ],
      "metadata": {
        "id": "OqsoJO65e2BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Supervised Model visualization"
      ],
      "metadata": {
        "id": "VucBbVtne4sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows = 4,ncols=1,figsize=(20,15),sharex=True)\n",
        "row = -1\n",
        "for metric in ['accuracy','precision','recall','F1']:\n",
        "  X = (DF.columns)\n",
        "  row += 1\n",
        "  y = DF.iloc[row]\n",
        "\n",
        "  ax[row].bar(X,y)\n",
        "  ax[row].set_ylabel(metric)\n",
        "\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EXDEH7nyewj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Ablation"
      ],
      "metadata": {
        "id": "rLzrG_ivfIgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = '/content/standard_scalar_model'\n",
        "pca_chosen = '/content/pca_model_8'\n",
        "kmeans_chosen = '/content/kmean_model_1'\n",
        "\n",
        "#standard_scalar_model\n",
        "with open(scalar, 'rb') as ss_file:\n",
        "    loaded_scalar_model = pickle.load(ss_file)\n",
        "\n",
        "# pca model chosen:\n",
        "with open(pca_chosen, 'rb') as pca_file:\n",
        "    loaded_pca_model = pickle.load(pca_file)\n",
        "\n",
        "with open('cluster_3_ComplementNB_1','rb') as file:\n",
        "  loaded_model = pickle.load(file)\n",
        "\n",
        "\n",
        "print('initializing test data scaling')\n",
        "test_data_scaled\n"
      ],
      "metadata": {
        "id": "J4bapxmafIx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ablated_accuracies = []\n",
        "# Perform feature ablation\n",
        "num_features = test_data_scaled.shape[1]\n",
        "\n",
        "for feature in range(num_features):\n",
        "    X_ablated = test_data_scaled.copy()\n",
        "    X_ablated[:, feature] = 0  # Set the feature values to 0\n",
        "\n",
        "    test_data_pca = loaded_pca_model.transform(X_ablated)\n",
        "    ablated_accuracy = accuracy_score(test_classifier_target,loaded_model.predict(test_data_pca))\n",
        "    ablated_accuracies.append(ablated_accuracy)\n",
        "\n",
        "    print(\"Feature {}: Ablated Accuracy: {:.4f}\".format(feature, ablated_accuracy))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.bar(range(num_features), ablated_accuracies[:num_features])\n",
        "plt.xlabel('Feature Index')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Feature Ablation')\n",
        "plt.xticks(range(num_features))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hFMZLMHWl9f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_means = loaded_model.theta_\n",
        "class_std = loaded_model.sigma_\n",
        "importance_scores = np.mean(class_means / class_std, axis=0)\n",
        "sorted_indicies = np.argsort(importance_scores)[::-1]\n",
        "feature_names = [\"Feature\"+str(x) for x in range(0,19)]\n",
        "print(\"Feature Importance:\")\n",
        "for i in sorted_indicies:\n",
        "    print(f\"{feature_names[int(i)]}: {importance_scores[int(i)]}\")"
      ],
      "metadata": {
        "id": "8hmWFZ0_mHvD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}